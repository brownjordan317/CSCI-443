{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "This notebook will serve as the primary means of documentation for creating an object detection model\n",
    "_______________________________________________________________________________________________________________________________________________\n",
    "\n",
    "### Full group includes:\n",
    "- Jordan Brown\n",
    "- Dylan Roy\n",
    "- Maxwell Barret\n",
    "- Julia Dewhurt\n",
    "\n",
    "### Primary notebook contributers:\n",
    "- \"\"\n",
    "- \"\"\n",
    "_______________________________________________________________________________________________________________________________________________\n",
    "\n",
    "***The primary notebook contributers are the group members who were assigned to this specific task. All group members will work in collaboration to create a final working product. However, the nature of this project calls for the full group to be assigned to primary tasks.***\n",
    "\n",
    "## Notebook Goal/Purpose\n",
    "\n",
    "This notebook will be used to create a model for traffic based object detection. This will involve using labeled image and video feeds to determine what traffic objects look like. This model will be able to detect and track traffic counts at individual intersections. This tracking will be used to create a dataset which can hopefully be used to train a traffic prediction for the traffic analysis portion of this project.\n",
    "_______________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cells should use the following layout template\n",
    "```\n",
    "\"\"\"\n",
    "At the top will be a commment block\n",
    "this comment block will describe the\n",
    "primary purpose for the cells code.\n",
    "\"\"\"\n",
    "\n",
    "# A comment stating used libary(s)\n",
    "\n",
    "Code\n",
    "    Implementation\n",
    "        Goes\n",
    "            Here\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell will contain the import statements for the notebook.\n",
    "\"\"\"\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# import os\n",
    "\n",
    "# Initialize the API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Dataset details\n",
    "dataset = \"imtkaggleteam/city-intersection-computer-vision\"\n",
    "download_path = \"dataset\"  # Desired directory\n",
    "\n",
    "# Ensure the download path exists\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "    # Download the dataset\n",
    "    api.dataset_download_files(dataset, path=download_path, unzip=True)\n",
    "\n",
    "    print(f\"Dataset downloaded to: {os.path.abspath(download_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, distutils.core\n",
    "from IPython.display import clear_output\n",
    "\n",
    "!python -m pip install pyyaml==5.1\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "\n",
    "import torch, detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "print(\"detectron2 version:\", detectron2.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, cv2, random\n",
    "from IPython import display\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "\n",
    "SEED = 12\n",
    "THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that used for creation a coco json file from a csv file\n",
    "# original reference -> https://stackoverflow.com/questions/62545034/how-to-convert-a-csv-table-into-coco-format-in-python\n",
    "\n",
    "def create_csv_to_coco(path, save_json_path):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data[['filename','class','width', 'height','xmin','ymin','xmax','ymax']]\n",
    "\n",
    "    images = []\n",
    "    categories = []\n",
    "    annotations = []\n",
    "\n",
    "    category = {}\n",
    "    category[\"supercategory\"] = 'none'\n",
    "    category[\"id\"] = 0\n",
    "    category[\"name\"] = 'None'\n",
    "    categories.append(category)\n",
    "\n",
    "    data['fileid'] = data['filename'].astype('category').cat.codes\n",
    "    data['categoryid']= pd.Categorical(data['class'],ordered= True).codes\n",
    "    data['categoryid'] = data['categoryid']+1\n",
    "    data['annid'] = data.index\n",
    "    \n",
    "    def image(row):\n",
    "        image = {}\n",
    "        image[\"height\"] = row.height\n",
    "        image[\"width\"] = row.width\n",
    "        image[\"id\"] = row.fileid\n",
    "        image[\"file_name\"] = row.filename\n",
    "        return image\n",
    "\n",
    "    def category(row):\n",
    "        category = {}\n",
    "        category[\"supercategory\"] = 'None'\n",
    "        category[\"id\"] = row.categoryid\n",
    "        category[\"name\"] = row[2]\n",
    "        return category\n",
    "\n",
    "    def annotation(row):\n",
    "        annotation = {}\n",
    "        area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
    "        annotation[\"segmentation\"] = []\n",
    "        annotation[\"iscrowd\"] = 0\n",
    "        annotation[\"area\"] = area\n",
    "        annotation[\"image_id\"] = row.fileid\n",
    "\n",
    "        annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
    "\n",
    "        annotation[\"category_id\"] = row.categoryid\n",
    "        annotation[\"id\"] = row.annid\n",
    "        return annotation\n",
    "\n",
    "    for row in data.itertuples():\n",
    "        annotations.append(annotation(row))\n",
    "\n",
    "    imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "    for row in imagedf.itertuples():\n",
    "        images.append(image(row))\n",
    "\n",
    "    catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "    for row in catdf.itertuples():\n",
    "        categories.append(category(row))\n",
    "\n",
    "    data_coco = {}\n",
    "    data_coco[\"images\"] = images\n",
    "    data_coco[\"categories\"] = categories\n",
    "    data_coco[\"annotations\"] = annotations\n",
    "    json.dump(data_coco, open(save_json_path, \"w\"), indent=4)\n",
    "    print( save_json_path ,' file created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_to_coco(f'{download_path}/train/_annotations.csv', \n",
    "                   'dataset/train_coco.json')\n",
    "create_csv_to_coco(f'{download_path}/valid/_annotations.csv', \n",
    "                   'dataset/valid_coco.json')\n",
    "create_csv_to_coco(f'{download_path}/test/_annotations.csv', \n",
    "                   'dataset/test_coco.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating coco instances\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "    \n",
    "register_coco_instances(f\"city_intersection_train_dataset\", {},\n",
    "                        f\"../working/train_coco.json\",\n",
    "                        f\"../input/city-intersection-computer-vision/train\")\n",
    "\n",
    "register_coco_instances(f\"city_intersection_valid_dataset\", {},\n",
    "                        f\"../working/valid_coco.json\",\n",
    "                        f\"../input/city-intersection-computer-vision/valid\")\n",
    "\n",
    "register_coco_instances(f\"city_intersection_test_dataset\", {},\n",
    "                        f\"../working/test_coco.json\",\n",
    "                        f\"../input/city-intersection-computer-vision/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples from the training dataset\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"city_intersection_train_dataset\")\n",
    "train_dataset_dicts = DatasetCatalog.get(\"city_intersection_train_dataset\")\n",
    "\n",
    "# A function that creates examples from the dataset\n",
    "def create_random_images(dataset_dict,dataset_metadata, seed, image_scale = 0.7):\n",
    "    np.random.seed(seed)\n",
    "    images = np.random.permutation(dataset_dict)[:2]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize = (12,6), dpi = 100)\n",
    "    for i in range(2):\n",
    "        im = images[i]\n",
    "        img_link = im['file_name']\n",
    "        img_id = im['image_id']\n",
    "        img = cv2.imread(img_link)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        visualizer = Visualizer(img, metadata= dataset_metadata, scale=image_scale)\n",
    "        vis = visualizer.draw_dataset_dict(im)\n",
    "        final_img = vis.get_image()\n",
    "        \n",
    "        axs[i].set_title('image id: ' + str(img_id), fontsize = 10)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].imshow(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples from the training dataset\n",
    "\n",
    "create_random_images(train_dataset_dicts, my_dataset_train_metadata, seed = 92, image_scale = 1)\n",
    "create_random_images(train_dataset_dicts, my_dataset_train_metadata, seed = 1, image_scale = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
