{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "This notebook will serve as the primary means of documentation for creating an object detection model\n",
    "_______________________________________________________________________________________________________________________________________________\n",
    "\n",
    "### Full group includes:\n",
    "- Jordan Brown\n",
    "- Dylan Roy\n",
    "- Maxwell Barret\n",
    "- Julia Dewhurt\n",
    "\n",
    "### Primary notebook contributers:\n",
    "- \"\"\n",
    "- \"\"\n",
    "_______________________________________________________________________________________________________________________________________________\n",
    "\n",
    "***The primary notebook contributers are the group members who were assigned to this specific task. All group members will work in collaboration to create a final working product. However, the nature of this project calls for the full group to be assigned to primary tasks.***\n",
    "\n",
    "## Notebook Goal/Purpose\n",
    "\n",
    "This notebook will be used to create a model for traffic based object detection. This will involve using labeled image and video feeds to determine what traffic objects look like. This model will be able to detect and track traffic counts at individual intersections. This tracking will be used to create a dataset which can hopefully be used to train a traffic prediction for the traffic analysis portion of this project.\n",
    "_______________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train2017...\n",
      "Downloaded COCO/train2017.zip\n",
      "Extracting train2017...\n",
      "Extracted COCO/train2017.zip to COCO\n",
      "Downloading val2017...\n",
      "Downloaded COCO/val2017.zip\n",
      "Extracting val2017...\n",
      "Extracted COCO/val2017.zip to COCO\n",
      "Downloading annotations...\n",
      "Downloaded COCO/annotations.zip\n",
      "Extracting annotations...\n",
      "Extracted COCO/annotations.zip to COCO\n",
      "COCO dataset downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "def download_file(url, destination):\n",
    "    \"\"\"\n",
    "    Download a file from a URL to a specified destination.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(destination, 'wb') as f:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {destination}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}\")\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"\n",
    "    Extract a zip file to a specified directory.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Extracted {zip_file} to {extract_to}\")\n",
    "\n",
    "def download_and_extract_coco(destination_dir):\n",
    "    \"\"\"\n",
    "    Download and extract the COCO dataset (2017 version) images and annotations.\n",
    "    \"\"\"\n",
    "    # Create destination directory if it doesn't exist\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "    # Define COCO dataset URLs\n",
    "    coco_urls = {\n",
    "        'train2017': 'http://images.cocodataset.org/zips/train2017.zip',\n",
    "        'val2017': 'http://images.cocodataset.org/zips/val2017.zip',\n",
    "        'annotations': 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
    "    }\n",
    "\n",
    "    # Download images and annotations\n",
    "    for name, url in coco_urls.items():\n",
    "        file_path = os.path.join(destination_dir, f\"{name}.zip\")\n",
    "        \n",
    "        print(f\"Downloading {name}...\")\n",
    "        download_file(url, file_path)\n",
    "        \n",
    "        # Extract the downloaded zip files\n",
    "        print(f\"Extracting {name}...\")\n",
    "        extract_zip(file_path, destination_dir)\n",
    "\n",
    "        # Remove zip files after extraction\n",
    "        os.remove(file_path)\n",
    "\n",
    "    print(\"COCO dataset downloaded and extracted successfully!\")\n",
    "\n",
    "# Check if the COCO dataset has already been downloaded\n",
    "if os.path.exists('COCO'):\n",
    "    print(\"COCO dataset already exists. Skipping download and extraction.\")\n",
    "    exit()\n",
    "    \n",
    "# Specify the directory to save the dataset\n",
    "destination_dir = 'COCO'\n",
    "\n",
    "# Start downloading and extracting COCO dataset\n",
    "download_and_extract_coco(destination_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import faster_rcnn\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# COCO Dataset Paths (adjust according to where you downloaded COCO dataset)\n",
    "train_img_dir = 'path/to/coco/train2017'\n",
    "val_img_dir = 'path/to/coco/val2017'\n",
    "train_annot_file = 'path/to/coco/annotations/instances_train2017.json'\n",
    "val_annot_file = 'path/to/coco/annotations/instances_val2017.json'\n",
    "\n",
    "# Load COCO datasets using torchvision's CocoDetection\n",
    "train_dataset = torchvision.datasets.CocoDetection(root=train_img_dir, annFile=train_annot_file, transform=transform)\n",
    "val_dataset = torchvision.datasets.CocoDetection(root=val_img_dir, annFile=val_annot_file, transform=transform)\n",
    "\n",
    "# DataLoader setup\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Load pre-trained Faster R-CNN model with a ResNet-50 backbone\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Modify the model to detect vehicles (2 classes: background and vehicle)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)  # 2 classes: background and vehicle\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {losses.item()}\")\n",
    "\n",
    "    # Validation (optional, to track the progress)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = [image.to(device) for image in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                predictions = model(images)\n",
    "                # Here, you can visualize the predictions or compute metrics like mAP\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'vehicle_detection_model.pth')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
