{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Implementation\n",
    "\n",
    "This code will contain the implementation for our pipeline that combines both our object detection and our traffic prediction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.callable_implementation import write_csv\n",
    "from object_detection.callable_implementation import process_image\n",
    "from object_detection.callable_implementation import get_dt_info\n",
    "from object_detection.callable_implementation import load_model\n",
    "from object_detection.callable_implementation import load_tensor_img\n",
    "from object_detection.render_video import images_to_video_ffmpeg\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "from queue import Queue\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model, vehicle_classes, device = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.4.111:8080\n"
     ]
    }
   ],
   "source": [
    "# read ip from text file\n",
    "with open('my_ip.txt', 'r') as f:\n",
    "    ip = f.read().strip()\n",
    "print(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating image: test_images/image_0.jpg\n",
      "Annotating image: test_images/image_1.jpg\n",
      "Annotating image: test_images/image_2.jpg\n",
      "Annotating image: test_images/image_3.jpg\n",
      "Annotating image: test_images/image_4.jpg\n",
      "Annotating image: test_images/image_5.jpg\n",
      "Annotating image: test_images/image_6.jpg\n",
      "Annotating image: test_images/image_7.jpg\n",
      "Annotating image: test_images/image_8.jpg\n",
      "Annotating image: test_images/image_9.jpg\n",
      "Annotating image: test_images/image_10.jpg\n",
      "Annotating image: test_images/image_11.jpg\n",
      "Annotating image: test_images/image_12.jpg\n",
      "Annotating image: test_images/image_13.jpg\n",
      "Annotating image: test_images/image_14.jpg\n",
      "Annotating image: test_images/image_15.jpg\n",
      "Estimated FPS: 4.0\n"
     ]
    }
   ],
   "source": [
    "RUNNING = True\n",
    "\n",
    "# Replace the below URL with your own. Make sure to add \"/shot.jpg\" at the last.\n",
    "url = f\"http://{ip}/shot.jpg\"\n",
    "\n",
    "# Initialize variables\n",
    "fps = 10  # Desired FPS for the output video\n",
    "out_dir = \"test_images\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Queue for storing images that need to be annotated and displayed\n",
    "image_queue = Queue()\n",
    "annotated_image_queue = Queue()\n",
    "\n",
    "# Function to process the image\n",
    "def annotate(image_path):\n",
    "    print(f\"Annotating image: {image_path}\")\n",
    "    output_path = 'live_stream'\n",
    "    image_base_name = os.path.basename(image_path).split('.')[0]\n",
    "    outfile_name = f'{image_base_name}_annotated.jpg'\n",
    "    img, img_tensor = load_tensor_img(image_path, device)\n",
    "    data, out_image = process_image(model, vehicle_classes, img, img_tensor, output_path, outfile_name)\n",
    "    time, day = get_dt_info()\n",
    "    data[\"Time\"] = time\n",
    "    data[\"Day of the week\"] = day\n",
    "    write_csv(data, \"test.csv\")\n",
    "    \n",
    "    # Save the annotated image\n",
    "    annotated_image_path = os.path.join(out_dir, outfile_name)\n",
    "    cv2.imwrite(annotated_image_path, out_image)\n",
    "\n",
    "    # Put the annotated image path in the annotated queue\n",
    "    annotated_image_queue.put(annotated_image_path)\n",
    "\n",
    "# Function to process images from the queue for annotation\n",
    "def process_annotations():\n",
    "    while True:\n",
    "        # Get an image path from the queue\n",
    "        img_path = image_queue.get()\n",
    "        if img_path is None:  # Sentinel value to stop the thread\n",
    "            break\n",
    "        # Call the annotation function for each image\n",
    "        annotate(img_path)\n",
    "        image_queue.task_done()\n",
    "\n",
    "# Function to display annotated images in a separate thread\n",
    "def display_annotated_images():\n",
    "    global RUNNING\n",
    "    while RUNNING:\n",
    "        # Get the annotated image path from the queue\n",
    "        annotated_img_path = annotated_image_queue.get()\n",
    "        if annotated_img_path is None:  # Sentinel value to stop the thread\n",
    "            break\n",
    "        \n",
    "        # Read and display the annotated image\n",
    "        annotated_img = cv2.imread(annotated_img_path)\n",
    "        cv2.imshow(\"Annotated Image\", annotated_img)\n",
    "        \n",
    "        # Press Esc key to exit the display window\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            RUNNING = False\n",
    "            break\n",
    "        annotated_image_queue.task_done()\n",
    "\n",
    "# Start the annotation processing thread\n",
    "annotation_thread = threading.Thread(target=process_annotations, daemon=True)\n",
    "annotation_thread.start()\n",
    "\n",
    "# Start the display thread\n",
    "display_thread = threading.Thread(target=display_annotated_images, daemon=True)\n",
    "display_thread.start()\n",
    "\n",
    "# Timing control to achieve 30 FPS\n",
    "prev_time = time.time()\n",
    "\n",
    "# While loop to continuously fetch data from the URL\n",
    "count = 0\n",
    "while RUNNING:\n",
    "    # Calculate the time difference\n",
    "    current_time = time.time()\n",
    "\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_arr, -1)\n",
    "    img = imutils.resize(img, width=1000, height=1800)\n",
    "\n",
    "    # Save the image with a timestamp to ensure uniqueness\n",
    "    filename = f\"{out_dir}/image_{count}.jpg\"\n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "    # Add the image path to the queue for annotation\n",
    "    image_queue.put(filename)\n",
    "\n",
    "    # # Display the image on the Android camera window\n",
    "    # cv2.imshow(\"Android_cam\", img)\n",
    "\n",
    "    # # Press Esc key to exit\n",
    "    # if cv2.waitKey(1) == 27:\n",
    "    #     break\n",
    "\n",
    "    # Sleep to avoid high CPU usage (sleeping 1ms in case timing isn't perfect)\n",
    "    time.sleep(1 / fps)\n",
    "    count += 1\n",
    "    \n",
    "\n",
    "# Stop the annotation and display threads gracefully\n",
    "image_queue.put(None)  # Sentinel to stop the annotation thread\n",
    "annotation_thread.join()\n",
    "\n",
    "annotated_image_queue.put(None)  # Sentinel to stop the display thread\n",
    "display_thread.join()\n",
    "\n",
    "cv2.destroyWindow(\"Annotated Image\")\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "total_run_time = time.time() - prev_time\n",
    "num_seconds = int(total_run_time)\n",
    "# get num images in live_stream folder\n",
    "num_images = len([name for name in os.listdir(\"live_stream\") if os.path.isfile(os.path.join(\"live_stream\", name))])\n",
    "estimated_fps = num_images / num_seconds\n",
    "print(f\"Estimated FPS: {estimated_fps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/27 13:34:18.520846 cmd_run.go:1138: WARNING: cannot start document portal: dial unix /run/user/1000/bus: connect: no such file or directory\n",
      "ffmpeg version n4.3.1 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix= --prefix=/usr --disable-debug --disable-doc --disable-static --enable-cuda --enable-cuda-sdk --enable-cuvid --enable-libdrm --enable-ffplay --enable-gnutls --enable-gpl --enable-libass --enable-libfdk-aac --enable-libfontconfig --enable-libfreetype --enable-libmp3lame --enable-libnpp --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libopus --enable-libpulse --enable-sdl2 --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libv4l2 --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxcb --enable-libxvid --enable-nonfree --enable-nvenc --enable-omx --enable-openal --enable-opencl --enable-runtime-cpudetect --enable-shared --enable-vaapi --enable-vdpau --enable-version3 --enable-xlib\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, image2, from 'live_stream/temp_ffmpeg/%04d.jpg':\n",
      "  Duration: 00:00:04.00, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1000x562 [SAR 1:1 DAR 500:281], 4 fps, 4 tbr, 4 tbn, 4 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x5611fd907340] deprecated pixel format used, make sure you did set range correctly\n",
      "[libx264 @ 0x5611fd852680] using SAR=1/1\n",
      "[libx264 @ 0x5611fd852680] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5611fd852680] profile High, level 3.1\n",
      "[libx264 @ 0x5611fd852680] 264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=4 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'live_stream_('133418', 'Wednesday').mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1000x562 [SAR 1:1 DAR 500:281], q=-1--1, 4 fps, 16384 tbn, 4 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as live_stream_('133418', 'Wednesday').mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   16 fps=0.0 q=-1.0 Lsize=     806kB time=00:00:03.25 bitrate=2032.3kbits/s speed=7.58x    \n",
      "video:805kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.119567%\n",
      "[libx264 @ 0x5611fd852680] frame I:4     Avg QP:19.44  size: 65518\n",
      "[libx264 @ 0x5611fd852680] frame P:10    Avg QP:20.92  size: 47406\n",
      "[libx264 @ 0x5611fd852680] frame B:2     Avg QP:21.25  size: 43909\n",
      "[libx264 @ 0x5611fd852680] consecutive B-frames: 75.0% 25.0%  0.0%  0.0%\n",
      "[libx264 @ 0x5611fd852680] mb I  I16..4:  2.4% 78.7% 18.9%\n",
      "[libx264 @ 0x5611fd852680] mb P  I16..4:  3.2% 54.5% 11.6%  P16..4: 15.3% 11.0%  4.3%  0.0%  0.0%    skip: 0.1%\n",
      "[libx264 @ 0x5611fd852680] mb B  I16..4:  1.6% 26.1%  6.5%  B16..8: 28.5% 18.4%  3.9%  direct:13.7%  skip: 1.2%  L0:36.3% L1:48.4% BI:15.3%\n",
      "[libx264 @ 0x5611fd852680] 8x8 transform intra:78.5% inter:68.7%\n",
      "[libx264 @ 0x5611fd852680] coded y,uvDC,uvAC intra: 89.7% 88.6% 69.2% inter: 75.0% 92.6% 16.6%\n",
      "[libx264 @ 0x5611fd852680] i16 v,h,dc,p: 17% 11%  3% 69%\n",
      "[libx264 @ 0x5611fd852680] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 25% 17%  4%  5%  6%  7%  5%  7%\n",
      "[libx264 @ 0x5611fd852680] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 36%  7%  4%  5%  5%  7%  4%  7%\n",
      "[libx264 @ 0x5611fd852680] i8c dc,h,v,p: 37% 27% 28%  9%\n",
      "[libx264 @ 0x5611fd852680] Weighted P-Frames: Y:10.0% UV:10.0%\n",
      "[libx264 @ 0x5611fd852680] ref P L0: 62.1% 28.4%  5.7%  3.4%  0.3%\n",
      "[libx264 @ 0x5611fd852680] ref B L0: 96.1%  3.9%\n",
      "[libx264 @ 0x5611fd852680] kb/s:1647.90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date_time_info = get_dt_info()\n",
    "images_to_video_ffmpeg(\"live_stream\", f\"live_stream_{date_time_info}.mp4\", estimated_fps)\n",
    "\n",
    "# remove live_stream folder and its contents\n",
    "shutil.rmtree(\"live_stream\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
